# 卷积神经网络
2012年Alex net的产生  
one-hot 编码是常用的对标签进行编码的一种方式  
1. 卷积层——CNN中独特的网络结构  
卷积的目的——进行图像的特征提取  
卷积的特性——1）拥有局部感知机制；2）权值共享  
卷积核的特性：1）卷积核的channel与输入特征层的channel相同；2）输出的特征矩阵channel与卷积核个数相同  
- 卷积加上偏置？也是可以的——直接加偏置就好，一个卷积核对应一个偏置
- 卷积后的激活函数  
为什么需要激活函数：引入非线性因素，使其具备解决非线性问题的能力  
2. 常见的激活函数：  
sigmoid：激活函数饱和时，梯度值非常小，故在网络层数较深时容易出现梯度消失  
Relu:f(x) = Max(0,x),缺点在于当反向传播过程中，有一个非常大的梯度经过时，反向传播更新后可能导致权重分布中心小于0，导致该处的倒数始终为0，反向传播无法更新权重，即进入失活状态——一旦失活，就再也激活不了  
**在训练过程中，建议在刚开始的时候，不能使用大的学习率，这样很可能导致很多神经元失活**
- 卷积过程中出现越界：
- 卷积操作后的尺寸 决定因素：
1）输入图片大小w×w
2）Filter大小F×F（卷积核的大小）
3）步长s
4）padding的像素数P
经卷积之后的矩阵的尺寸大小计算公式：
![](https://img-blog.csdnimg.cn/247a1b214682440a894ff1887c51f906.png)

3. 池化层——目的：对特征图进行稀疏处理，减少数据运算量  
池化层的特点：
- 没有训练参数
- 只改变特征矩阵的w和h，不改变channel
- 一般poolsize和stride的值相同


