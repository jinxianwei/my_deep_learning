
ptorch tensor 的通道排序：[batch, channel, height, width]  
PIL.Image.open()   .size得到[width, height]  
可视化tensor图片，需要更改通道np.transpose(npimg, (1,2,0))  
transforms.ToTensor()将PIL Image或numpy.ndarray 的（H W C）-->(C H W),并将其值从[0,255]-->[0.0,1.0]  
在pytorch中搭建模型，流程：定义一个继承自nn.Moduel的类，在类中实现两个方法：  
在初始化函数中，首先继承父类，然后实现在搭建网络过程中需要使用到的一系列层结构  
在forward函数中，定义正向传播的过程
```python
class LeNet(nn.Module):
    def __init__(self):
        super(LeNet, self).__init__()
        # 涉及到多继承时，继承父类的构造函数
        self.conv1 = nn.Conv2d(3, 16, 5)
        # outchannels=16,对应的就是使用的卷积核的个数，使用几个卷积核，
        # 就会生成多少维度的张量
        self.pool1 = nn.MaxPool2d(2, 2) # 池化核大小和步距
        self.conv2 = nn.Conv2d(16, 32, 5)   # 14-5+2x0  /1 +1=10
        self.pool2 = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(32*5*5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))    # input(3, 32, 32) output(16, 28, 28)
        x = self.pool1(x)            # output(16, 14, 14)
        x = F.relu(self.conv2(x))    # output(32, 10, 10)
        x = self.pool2(x)            # output(32, 5, 5)
        x = x.view(-1, 32*5*5)       # output(32*5*5)
        x = F.relu(self.fc1(x))      # output(120)
        x = F.relu(self.fc2(x))      # output(84)
        x = self.fc3(x)              # output(10)
        return x

        # 注意：网络里没有用softmax，一般在分类问题上会接上一层
        #softmax层，将输出转化成一个概率分布，理论上确实是这样做
        # 但是，在pytorch计算交叉熵的内部，已经实现了一个更加高效的softmax方法
```
虚拟生成一个数据，输入网络，考察输出的数据尺寸
```python
if __name__ == "__main__":
    model = LeNet()
    # print(model)
    # input = torch.rand([32,3,32,32])
    input = torch.rand(32,3,32,32)
    output = model(input)
    print(output.shape)
```

```python
transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) 
```
transforms.ToTensor()将PIL Image或numpy.ndarray 的（H W C）-->(C H W),并将其值从[0,255]-->[0.0,1.0]

```python
    def imshow(img):
        img = img/2+0.5  # 去标准化
        npimg = img.numpy()  # 由tensor转为numpy，为了显示图片
        plt.imshow(np.transpose(npimg, (1,2,0)))  # 1，2，0是tensor中的索引
        #将tensor的通道；高度；宽度 转换为图像原始的情况：高度；宽度；通道
        plt.show()
    print(' '.join('%5s' % classes[val_label[j]] for j in range(5)))
    imshow(torchvision.utils.make_grid(val_image))
```

由tensor转为numpy：nping = img.numpy()

```python
    net = LeNet()
    loss_function = nn.CrossEntropyLoss() # 在CrossEntropyLoss()中包含了logsoftmax，所以网络搭建的最后只到全连接层为止
    optimizer = optim.Adam(net.parameters(), lr=0.001)  # 优化器是用来计算损失梯度的
```

```python


    for epoch in range(5):  # loop over the dataset multiple times，
        #epoch代表将训练集迭代多少轮，训练集迭代完成一次之后会进行shuffle

        running_loss = 0.0
        for step, data in enumerate(train_loader, start=0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data

            # zero the parameter gradients
            optimizer.zero_grad() # 将历史损失梯度清零
            # forward + backward + optimize
            outputs = net(inputs)
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()

            # print statistics
            running_loss += loss.item()  # 这里的loss的累加，是一个epoch中每500步的loss总和
            if step % 500 == 499:    # print every 500 mini-batches
                with torch.no_grad():  # with是一个上下文管理器，
                # with 。。。是说：在接下来的代码中，不要去计算误差累积节点的梯度
                # 否则：会占用更多的算力，消耗更多的资源；由于需要存储每个节点的损失梯度，将会占用更多的内存资源
                    outputs = net(val_image)  # [batch, 10]
                    predict_y = torch.max(outputs, dim=1)[1] # 获得网络预测最可能归于哪个类别的；[1]代表只需要知道索引就行了
                    accuracy = torch.eq(predict_y, val_label).sum().item() / val_label.size(0)
                    # 求得本次预测中，一共预测对了多少个样本
                    print('[%d, %5d] train_loss: %.3f  test_accuracy: %.3f' %
                          (epoch + 1, step + 1, running_loss / 500, accuracy))
                    running_loss = 0.0
```
optimizer.zero_grad() # 将历史损失梯度清零：如果不清除历史梯度，就会对计算的历史梯度进行累加（通过此特性能够变相实现一个很大的batch数值的训练）

enumerate函数的考察  
```python
x = [1,2,3,4,5,6,7,8,9,0]
for i, data in enumerate(x, start=2):  # start默认从0开始，可以指定初始值，对应i
    print(i, data)
```
保存网络参数
```python
    save_path = './Lenet.pth'
    torch.save(net.state_dict(), save_path)
```
---------------------
**预测**  
生成模型，并导入权重
```python
    net = LeNet()
    net.load_state_dict(torch.load('Lenet.pth')) # 载入保存的网络的权重数据
```
读入图片，并实施与训练相同的预处理，转为tensor后，再添加一个新的batch维度
```python
    transform = transforms.Compose(
                [transforms.Resize((32, 32)),
                transforms.ToTensor(),  # 这里将PIL Image 或numpy格式转为了tensor，并将其维度改变了
                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
    im = Image.open('trytest.png')
    im = transform(im)  # [C, H, W]
    im = torch.unsqueeze(im, dim=0)  # [N, C, H, W] 在其最前面，添加一个默认的值为1的维度   
```
输入网络，并预测
```python
    with torch.no_grad():
        outputs = net(im)
        predict = torch.max(outputs, dim=1)[1].data.numpy() # 通过torch.max可以得到两个信息，
        # 最大值和其索引，只需要其索引就好，dim=1的维度上找最大值，因为dim=0是batch维度，可以压缩掉的
        probablity = torch.softmax(outputs, dim=1) # dim=0的维度是batch信息
    print(classes[int(predict)])
    print(probablity) # 可见在概率中，最大值的位置在0处，其所指的类别就是plane的类别
```

